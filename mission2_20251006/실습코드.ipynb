{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc888c36",
   "metadata": {},
   "source": [
    "# 미션 2: 카카오 대화 요약\n",
    "\n",
    "\n",
    "## 🎯 학습 목표\n",
    "\n",
    "이 미션에서는 카카오톡 대화 내역을 분석하고 요약하는 AI 서비스를 개발합니다.\n",
    "\n",
    "### 주요 학습 내용\n",
    "- 대화형 텍스트 데이터 처리\n",
    "- 멀티턴 대화 요약 기법\n",
    "- 화자별 대화 분리 및 분석\n",
    "\n",
    "## 📝 실습 내용\n",
    "\n",
    "### 구현 기능\n",
    "- 카카오톡 대화 데이터 파싱\n",
    "- 화자별 대화 분리\n",
    "- 대화 내용 요약\n",
    "- 주요 키워드 추출\n",
    "\n",
    "### 사용 기술\n",
    "- Python\n",
    "- OpenAI API / LangChain\n",
    "- Jupyter Notebook\n",
    "\n",
    "\n",
    "### LLM 모델\n",
    "- gpt-3.5-turb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c887af",
   "metadata": {},
   "source": [
    "## 라이브러리 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f5dd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 파싱\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# AI\n",
    "import time\n",
    "import openai\n",
    "import anthropic\n",
    "import google.generativeai as genai\n",
    "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "786dfa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "ANTHROPIC_API_KEY = os.environ['ANTHROPIC_API_KEY']\n",
    "GOOGLE_API_KEY = os.environ['GOOGLE_API_KEY']\n",
    "OPENAI_API_KEY = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1da9bd",
   "metadata": {},
   "source": [
    "## 카카오톡 대화 데이터 파싱 & 화자별 대화 분리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153c0e9f",
   "metadata": {},
   "source": [
    "### Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f2ac9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations = []\n",
    "paths = glob.glob('./res/297.SNS_데이터_고도화/01-1.정식개방데이터/Training/02.라벨링데이터/TL/*json')\n",
    "target_count = 20\n",
    "count = 0\n",
    "for path in paths:\n",
    "    with open(path, 'r') as f:\n",
    "        conv_dict = json.load(f)\n",
    "        # 2 명 선택\n",
    "        if conv_dict['header']['dialogueInfo']['numberOfParticipants'] == 2:\n",
    "            # 30 글자 이상\n",
    "            if conv_dict['header']['dialogueInfo']['numberOfUtterances'] > 30:\n",
    "                conv_list = []\n",
    "                for d in conv_dict['body']:\n",
    "                    conv_list.append(d['participantID'] + ': ' + d['utterance'])\n",
    "                if conv_list[0] == conv_list[1]:\n",
    "                    continue\n",
    "                conv_text = '\\n'.join(conv_list)\n",
    "                conversations.append(conv_text)\n",
    "                if count == target_count:\n",
    "                    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11f6b818",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./res/train_data.pickle', 'wb') as f:\n",
    "    pickle.dump(conversations, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46df8870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['P01: 매직해도 머릿결 안상함?',\n",
       " 'P01: 얇아지거나 전혀 영향없나 요샌...',\n",
       " 'P02: 상하지 얇아지진 않즈 키키',\n",
       " 'P02: 얇아지는건 두피건강이니까',\n",
       " 'P02: 근데 매직 정도는 마니 안 상하게 충분히 가능',\n",
       " 'P01: **샘한테 얼마주고 햇우',\n",
       " 'P01: 나도 머리 이번엔 좀 길러봐야겠엉',\n",
       " 'P02: 5마넌 줬어',\n",
       " 'P02: 3마넌 달라길래.ㅌㅌ',\n",
       " 'P01: 키키 야귀엽누 키키',\n",
       " 'P01: 다른데가서 니 머리 길이 매직이면 10은 거뜬히 나올 텐데',\n",
       " 'P02: 애매한게 내가 샘머리 짤라줬거든',\n",
       " 'P02: 난 뿌리매직만 하공',\n",
       " 'P02: 키키 긍서 2마넌 달라는 거야',\n",
       " 'P02: 글서 쌤 너무 심한거 아니에요? 이러니까 3달래',\n",
       " 'P01: 키키',\n",
       " 'P02: 글서 5쥼 키키',\n",
       " 'P01: 나 장염땜에 어제 하루종일 비워냇는데도 계속먹어서 그런지 살이 1도 안빠졌네...',\n",
       " 'P02: 내가 양꼬치도 사줫거든 키키',\n",
       " 'P02: 장염을 이기는 식이네',\n",
       " 'P01: 장염 걸리면 수분이라도 빠져서 무게빠지는게 국룰인데...',\n",
       " 'P02: 그러니깐 키키',\n",
       " 'P02: 근데 나도 그렇더라',\n",
       " 'P02: 먹으니까 이기더라',\n",
       " 'P01: 키키 아침에 일어났는데 몸이 가벼운느낌이 아니라 부은 느낌이엇어 키키',\n",
       " 'P02: 키키 웃겨',\n",
       " 'P02: 어젯밤에 많이 먹었니',\n",
       " 'P01: 어제밤에 생라면을 좀 먹긴했지... 키키 짯나...?',\n",
       " 'P01: 짠과자가 땡기더라구 키키',\n",
       " 'P01: 다이어트 언제하니',\n",
       " 'P02: 키키 다이어트 오늘부터 하자...']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversations[-2].split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0708cbea",
   "metadata": {},
   "source": [
    "### 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35d0e401",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations = []\n",
    "\n",
    "paths = glob.glob('./res/297.SNS_데이터_고도화/01-1.정식개방데이터/Validation/02.라벨링데이터/VL/*json')\n",
    "target_count = 20\n",
    "count = 0\n",
    "for path in paths:\n",
    "    with open(path, 'r') as f:\n",
    "        conv_dict = json.load(f)\n",
    "        if conv_dict['header']['dialogueInfo']['numberOfParticipants'] == 2:\n",
    "            if conv_dict['header']['dialogueInfo']['numberOfUtterances'] > 30:\n",
    "                conv_list = []\n",
    "                for d in conv_dict['body']:\n",
    "                    conv_list.append(d['participantID'] + ': ' + d['utterance'])\n",
    "                if conv_list[0] == conv_list[1]:\n",
    "                    print('Repeated Conversations')\n",
    "                    continue\n",
    "                conv_text = '\\n'.join(conv_list)\n",
    "                conversations.append(conv_text)\n",
    "                if count == target_count:\n",
    "                    break\n",
    "count = 0\n",
    "target_count = 30\n",
    "for path in paths:\n",
    "    with open(path, 'r') as f:\n",
    "        conv_dict = json.load(f)\n",
    "        if conv_dict['header']['dialogueInfo']['numberOfParticipants'] > 2:\n",
    "            if conv_dict['header']['dialogueInfo']['numberOfUtterances'] > 30:\n",
    "                conv_list = []\n",
    "                for d in conv_dict['body']:\n",
    "                    conv_list.append(d['participantID'] + ': ' + d['utterance'])\n",
    "                if conv_list[0] == conv_list[1]:           \n",
    "                    continue\n",
    "                conv_text = '\\n'.join(conv_list)\n",
    "                conversations.append(conv_text)\n",
    "                if count == target_count:\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "796753b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3577494/2244774912.py:11: DeprecationWarning: The model 'claude-3-5-sonnet-20240620' is deprecated and will reach end-of-life on October 22, 2025.\n",
      "Please migrate to a newer model. Visit https://docs.anthropic.com/en/docs/resources/model-deprecations for more information.\n",
      "  message = client.messages.create(\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"You are given a conversation among three users below. Imagine what the users discussed prior to the conversation.\n",
    "Please write the previous content, strictly following the tone and format of given conversation, with at least 3000 characters.\n",
    "\n",
    "{conversations[-2]}\n",
    "\"\"\"\n",
    "\n",
    "client = anthropic.Anthropic(\n",
    "    api_key=os.environ['ANTHROPIC_API_KEY']\n",
    ")\n",
    "\n",
    "message = client.messages.create(\n",
    "    model=\"claude-3-5-sonnet-20240620\",\n",
    "    max_tokens=4096,\n",
    "    temperature=0.0,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a84c84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = message.content[0].text.split('\\n\\n')[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4294fbf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "956a53aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./res/conv_long.pickle', 'rb') as f:\n",
    "    conv_long = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed76f28b",
   "metadata": {},
   "source": [
    "### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92734b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations = []\n",
    "\n",
    "paths = glob.glob('./res/297.SNS_데이터_고도화/01-1.정식개방데이터/Validation/02.라벨링데이터/VL/*json')\n",
    "target_count = 20\n",
    "count = 0\n",
    "\n",
    "for path in paths:\n",
    "    with open(path, 'r') as f:\n",
    "        conv_dict = json.load(f)\n",
    "        if conv_dict['header']['dialogueInfo']['numberOfParticipants'] == 2:\n",
    "            if conv_dict['header']['dialogueInfo']['numberOfUtterances'] > 30:\n",
    "                conv_list = []\n",
    "                for d in conv_dict['body']:\n",
    "                    conv_list.append(d['participantID'] + ': ' + d['utterance'])\n",
    "                if conv_list[0] == conv_list[1]:\n",
    "                    print('Repeated Conversations')\n",
    "                    continue\n",
    "                conv_text = '\\n'.join(conv_list)\n",
    "                conversations.append(conv_text)\n",
    "                count += 1\n",
    "                if count == target_count:\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bddfc102",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_count = 30\n",
    "count = 0\n",
    "\n",
    "for path in paths:\n",
    "    with open(path, 'r') as f:\n",
    "        conv_dict = json.load(f)\n",
    "        if conv_dict['header']['dialogueInfo']['numberOfParticipants'] > 2:\n",
    "            if conv_dict['header']['dialogueInfo']['numberOfUtterances'] > 30:\n",
    "                conv_list = []\n",
    "                for d in conv_dict['body']:\n",
    "                    conv_list.append(d['participantID'] + ': ' + d['utterance'])\n",
    "                if conv_list[0] == conv_list[1]:\n",
    "                    continue\n",
    "                conv_text = '\\n'.join(conv_list)\n",
    "                conversations.append(conv_text)\n",
    "                count += 1\n",
    "                if count == target_count:\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47cec7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./res/conv_long.pickle', 'rb') as f:\n",
    "    conv_long = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "830ac754",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations[-2] = '\\n'.join(conv_long) + '\\n' + conversations[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23511796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'P02: 야 요즘 뭐하고 지내?\\nP01: 나? 그냥 평소처럼 일하고 집에서 쉬고 그러지\\nP01: 너는?\\nP03: 나도 비슷해\\nP03: 요즘 코로나 때문에 밖에 나가기도 좀 그렇고\\nP02: 맞아 나도 그래\\nP02: 그래서 집에서 할 거 찾다가 넷플릭스 보고 있어\\nP01: 아 맞다 넷플릭스\\nP01: 나도 요즘 넷플릭스 많이 보는데\\nP03: 나는 유튜브를 더 많이 보는 것 같아\\nP03: 넷플릭스는 가끔씩?\\nP02: 유튜브도 좋지\\nP02: 근데 넷플릭스는 화질이 좋잖아\\nP01: 그러게\\nP01: 나는 넷플릭스랑 유튜브 둘 다 많이 봐\\nP03: 그래? 넷플릭스에서 뭐 재밌는 거 봤어?\\nP02: 나는 요즘 범죄 다큐멘터리 보고 있어\\nP02: 넷플릭스에 그런 거 많더라고\\nP01: 오 범죄 다큐멘터리?\\nP01: 나는 그런 건 잘 못 봐\\nP01: 무서워서...\\nP03: 나도 그런 건 별로야\\nP03: 차라리 코미디나 로맨스 같은 거 보는 게 나아\\nP02: 키키 그래?\\nP02: 난 오히려 그런 게 재밌던데\\nP01: 각자 취향이 다른가 보다\\nP01: 나는 요즘 한국 드라마를 많이 봐\\nP03: 한국 드라마?\\nP03: 뭐 봤는데?\\nP01: 응 킹덤이랑 스위트홈 봤어\\nP01: 둘 다 넷플릭스 오리지널이야\\nP02: 아 나도 킹덤 봤어!\\nP02: 좀비물인데 재밌더라고\\nP03: 난 그런 건 또 무서워서 못 봐\\nP03: 그냥 가벼운 로맨스 코미디가 좋아\\nP01: 키키 그래?\\nP01: 로맨스 코미디 추천해줘\\nP03: 음... 나는 최근에 청춘기록 봤어\\nP03: 박보검이랑 박소담 나오는 거\\nP02: 아 그거 들어본 것 같아\\nP02: 근데 난 안 봤어\\nP01: 나도 안 봤는데 어때?\\nP03: 나는 재밌게 봤어\\nP03: 배우들도 예쁘고 잘생겼고\\nP02: 키키 역시 외모 보는구나\\nP01: 그러게 키키\\nP01: 나도 배우 외모 보고 드라마 고르는 편이야\\nP03: 아니야 내용도 좋았어!\\nP03: 청춘들의 고민이랑 성장을 다루는데 공감되더라고\\nP02: 그렇구나\\nP02: 나도 한번 봐야겠다\\nP01: 나도 관심 생겼어\\nP01: 근데 넷플릭스에 있어?\\nP03: 아니 그건 티빙에서 봤어\\nP02: 아 그렇구나\\nP02: 난 넷플릭스만 구독하고 있어서...\\nP01: 나도 넷플릭스만 있어\\nP01: 다른 건 아직 안 썼는데 어때?\\nP03: 티빙도 괜찮아\\nP03: 근데 넷플릭스가 제일 컨텐츠 많은 것 같아\\nP02: 그러게\\nP02: 넷플릭스는 외국 드라마나 영화도 많고\\nP01: 맞아 외국 거 보기에는 넷플릭스가 최고인 것 같아\\nP03: 그래도 한국 드라마 보려면 다른 것도 필요해\\nP03: 왓챠나 티빙 같은 거\\nP02: 음 그렇긴 하지\\nP02: 근데 난 그냥 넷플릭스로 만족해\\nP01: 나도 그래\\nP01: 어차피 다 볼 시간도 없고...\\nP03: 그것도 그러네\\nP03: 시간이 없지...\\nP02: 맞아 시간이 문제야\\nP02: 일하느라 바빠서 드라마 볼 시간이 없어\\nP01: 나는 주말에 몰아서 보는 편이야\\nP01: 평일엔 진짜 시간이 없으니까\\nP03: 나도 그래\\nP03: 주말에 쉬면서 보는 게 제일 좋아\\nP02: 아 그렇게 보는구나\\nP02: 난 조금씩 매일 보는 편인데\\nP01: 어떤 게 더 좋아?\\nP02: 음... 난 매일 조금씩 보는 게 좋아\\nP02: 기다리는 맛도 있고\\nP03: 아 그렇구나\\nP03: 난 기다리는 거 못 참아서 몰아서 봐\\nP01: 나도 몰아서 보는 게 좋아\\nP01: 궁금해서 참기 힘들어\\nP02: 키키 그래?\\nP02: 난 오히려 기다리는 게 재밌어\\nP03: 역시 사람마다 다르구나\\nP01: 그러게\\nP01: 보는 방식도 다르고 취향도 다르고\\nP02: 맞아 각자 취향대로 보면 되는 거지\\nP03: 그래 뭐가 맞고 틀리고는 없으니까\\nP01: 그러게 키키\\nP01: 그래서 넷플릭스 말고 다른 거 쓰는 사람 없어?\\nP02: 난 넷플릭스만 써\\nP02: 딱히 다른 거 필요성을 못 느껴서\\nP03: 나는 티빙이랑 왓챠도 써\\nP03: 한국 드라마 보려고\\nP01: 아 그렇구나\\nP01: 비용은 어때? 많이 들어?\\nP03: 음... 좀 들긴 하지\\nP03: 근데 케이블 TV 끊고 이걸로 대체해서 괜찮아\\nP02: 아 그렇게 하는구나\\nP02: 난 그냥 넷플릭스만 있어도 충분해서\\nP01: 나도 넷플릭스로 만족하고 있어\\nP01: 근데 가끔 한국 드라마 보고 싶을 때가 있긴 해\\nP03: 그럴 땐 티빙이나 왓챠가 좋지\\nP03: 아니면 유튜브에서 짧은 클립이라도 보고\\nP02: 오 그것도 괜찮겠다\\nP02: 유튜브에 많이 올라오나?\\nP01: 응 요즘은 유튜브에 클립 많이 올라와\\nP01: 주요 장면 이런 거\\nP03: 맞아 하이라이트 같은 거\\nP02: 아 그렇구나\\nP02: 그럼 그걸로 대충 내용 파악할 수 있겠네\\nP01: 응 어느 정도는 가능해\\nP01: 근데 역시 전체를 다 보는 게 제일 좋지\\nP03: 그러게\\nP03: 클립만 보면 맥락을 모르니까\\nP02: 그렇긴 하지\\nP02: 그래도 시간 없을 때는 그렇게라도 보는 게 낫겠다\\nP01: 맞아 그래도 안 보는 것보단 낫지\\nP03: 그러게\\nP03: 근데 요즘 티비는 잘 안 보게 되는 것 같아\\nP01: 요즘은 티비보다는 역시 넷플릭스인가?\\nP01: 시간 맞춰서 볼 필요도 없고 편한 거 같아\\nP01: 요즘은 티비보다는 역시 넷플릭스인가?\\nP01: 시간 맞춰서 볼 필요도 없고 편한 거 같아\\nP02: 역시 그렇지\\nP02: 다들 오징어 게임 봤어?\\nP03: 응 봤는데 재밌더만 아줔 키키\\nP01: 나는 이정재 배우가 너무 멋있는 거 같아...\\nP01: 오징어 게임에서는 조금 찌질하게 나오긴 하는데 그래도 연기도 잘하고 너무 좋아\\nP02: 그치...\\nP02: 어느 영화든 존재감이 대단하긴 해\\nP03: 그래...\\nP03: 이정재가 거기서 좀 책임감 없는 역할로 나오더만\\nP03: 거기 나오는 사람들 모두 다 결핍도 있고 단점이 있는 듯\\nP01: 그렇지 그렇지\\nP01: 이정재는 보통 다 영화만 찍지 않아?\\nP02: 그치\\nP02: 드라마에서는 못 본 거 같아 난\\nP03: 아냐\\nP03: 최근에 보좌관 드라마도 찍었자나\\nP01: 보좌관 드라마는 뭐야?\\nP01: 그런 것도 있었어?\\nP02: 그러게\\nP02: 난 처음 들어본다\\nP02: 재밌어?\\nP03: 난 안 봤지\\nP03: 신민아랑 이정재 나옴...\\nP03: 시즌 2까지 나온 듯\\nP01: 나도 처음 들어봤어...\\nP01: 드라마를 요즘 안 봐서...\\nP01: 시즌 2까지 나왔으면 성공한 거 아냐?\\nP02: 그치\\nP02: 시즌 2면 성공했지...\\nP02: 머 다른 재밌는 거 없나 넷플릭스\\nP03: 모르겠다...\\nP03: 재밌어 하는 사람들도 있었겠지?\\nP01: 키키 그렇겠지? 키키\\nP01: 넷플릭스에서도 드라마를 요즘 안 봐 ㅠ\\nP02: 키키 그 오티스의 비밀 상담소 있는데 봐봐\\nP02: 재밌어\\nP03: 그래 뭘 봐...\\nP03: 이제 그만 봐\\nP03: 공부해 그냥...\\nP03: 무슨 드라마여\\nP01: 키키 그니까 공부 좀 하자...\\nP01: 근데 나는 오티스의 비밀 상담소 이미 다 봤어 하하\\nP02: 키키 얼마 전에 나온 시즌 3까지 다?\\nP03: 오 그렇구만\\nP03: 나도 봄\\nP03: 오티스 비밀상담소 이젠 그냥 재미없어진 듯\\nP01: 시즌 3가 나왔어?\\nP01: 언제 나왔어?\\nP02: 나온 지 한 달? 정도 된 거 같은데 나도 아직 안 봤거든\\nP03: 응응 그냥 그럼 여주랑 이어졌는데 마지막에 여주 유학 감'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversations[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed397ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./res/eval_data.pickle', 'wb') as f:\n",
    "    pickle.dump(conversations, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79d6ef68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_data():\n",
    "    with open('./res/eval_data.pickle', 'rb') as f:\n",
    "        eval_data = pickle.load(f)\n",
    "\n",
    "    return eval_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1614ab",
   "metadata": {},
   "source": [
    "## 대화 내용 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a03aa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f6f1b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shorten_conv(conversation):\n",
    "    shortened_len = len(conversation)\n",
    "    lst = conversation.split('\\n')\n",
    "    for i, l in enumerate(lst):\n",
    "        utterance_len = len(l)\n",
    "        shortened_len -= utterance_len\n",
    "        if shortened_len <= MAX_LEN:\n",
    "            break\n",
    "\n",
    "    lst_shortened = lst[i+1:]\n",
    "    conv_shortened = '\\n'.join(lst_shortened)\n",
    "    return conv_shortened\n",
    "\n",
    "\n",
    "def summarize(conversation, prompt, temperature=0.0, model='gpt-4.1-nano'):\n",
    "    if len(conversation) > MAX_LEN:\n",
    "        conversation = shorten_conv(conversation)\n",
    "\n",
    "    prompt = prompt + '\\n\\n' + conversation\n",
    "\n",
    "    if 'gpt' in model:\n",
    "        client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "        completion = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[{'role': 'user', 'content': prompt}],\n",
    "            temperature=temperature\n",
    "        )\n",
    "\n",
    "        return completion.choices[0].message.content\n",
    "    elif 'gemini' in model:\n",
    "        genai.configure(api_key=GOOGLE_API_KEY)\n",
    "        client = genai.GenerativeModel(model)\n",
    "        response = client.generate_content(\n",
    "            contents=prompt,\n",
    "            safety_settings={\n",
    "                HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE\n",
    "            }\n",
    "        )\n",
    "        time.sleep(1)\n",
    "\n",
    "        return response.text\n",
    "    elif 'claude' in model:\n",
    "        client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)\n",
    "        message = client.messages.create(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=temperature,\n",
    "            max_tokens=1024\n",
    "        )\n",
    "\n",
    "        return message.content[0].text\n",
    "\n",
    "\n",
    "def get_train_data():\n",
    "    with open('./res/train_data.pickle', 'rb') as f:\n",
    "        train_data = pickle.load(f)\n",
    "\n",
    "    return train_data\n",
    "\n",
    "\n",
    "def get_summary_prompt():\n",
    "    conv_train = get_train_data()[18]\n",
    "\n",
    "    prompt = f\"\"\"당신은 요약 전문가입니다. 사용자 대화들이 주어졌을 때 요약하는 것이 당신의 목표입니다. 대화를 요약할 때는 다음 단계를 따라주세요:\n",
    "\n",
    "1. 대화 참여자 파악: 대화에 참여하는 사람들의 수와 관계를 파악합니다.\n",
    "2. 주제 식별: 대화의 주요 주제와 부차적인 주제들을 식별합니다.\n",
    "3. 핵심 내용 추출: 각 주제에 대한 중요한 정보나 의견을 추출합니다.\n",
    "4. 감정과 태도 분석: 대화 참여자들의 감정이나 태도를 파악합니다.\n",
    "5. 맥락 이해: 대화의 전반적인 맥락과 배경을 이해합니다.\n",
    "6. 특이사항 기록: 대화 중 특별히 눈에 띄는 점이나 중요한 사건을 기록합니다.\n",
    "7. 요약문 작성: 위의 단계에서 얻은 정보를 바탕으로 간결하고 명확한 요약문을 작성합니다.\n",
    "각 단계를 수행한 후, 최종적으로 전체 대화를 200자 내외로 요약해주세요.\n",
    "\n",
    "아래는 예시 대화와 예시 요약 과정 및 결과 입니다.\n",
    "\n",
    "예시 대화:\n",
    "{conv_train}\n",
    "\n",
    "예시 요약 과정\n",
    "1. \"우리 대학교 졸업 여행 간 거 기억나?\"라는 언급과 전반적으로 친밀한 대화 톤을 사용하고 있는 것을 보았을 떄 두 사용자는 오랜 친구 사이로 보입니다.\n",
    "대화의 시작 부분에서 \"코로나가 좀 잠잠해지면 해외여행 중에 가고 싶은 곳 있어?\"라고 묻고 있는 것을 보았을 때 코로나 이후 가고 싶은 해외 여행지에 대해 논의하고 있습니다.\n",
    "따라서 다음과 같이 요약 할 수 있습니다:\n",
    "최소 대학 생활부터 함께 한 매우 친밀한 사이의 두 사용자가 코로나가 잠잠해졌을 때 방문하고 싶은 해외 여행지에 대해 일상적이고 가벼운 톤으로 대화하고 있습니다.\n",
    "\n",
    "2. 대화 중 호주, 일본, 하와이, 괌, 베트남 다낭, 스위스, 유럽들이 언급하고 있습니다.\n",
    "남편의 첫 직장 워크샵, 대학교 졸업 여행, 호주 워킹홀리데이 등의 경험을 이야기하면서 과거 여행 경험을 공유하며 추억을 회상하고 있습니다.\n",
    "따라서 다음과 같이 요약 할 수 있습니다:\n",
    "여행지로는 하와이, 괌, 스위스, 호주, 베트남 다낭 등을 언급하며 남편과의 연락 관련 다툼이나 졸업여행 관련 추억을 회상합니다.\n",
    "\n",
    "3. 소매치기, 여권 분실, 인도에서의 여성 여행자 위험 등을 언급하며 해외 여행의 위험성에 대해 우려를 표현하고 있습니다.\n",
    "\"해외 여행 가면 가이드 안 끼고 가면 영어 실력 엄청 좋은 사람이랑 가는 거 아닐 땐 소통 문제도 좀 곤란할 때가 있는 거 같아\"라는 언급과 \"왜 영어 공부를 열심히 안 했을까... 후회\"라는 표현이 있는 것을 보았을 때 언어 장벽의 어려움을 인식하고 영어 실력 향상에 대한 욕구를 표현합니다.\n",
    "따라서 다음과 같이 요약 할 수 있습니다:\n",
    "또한 여행 중 발생하는 위험에 대한 우려도 표하고 있으며, 해외여행 시 언어 장벽의 어려움을 인식하고 영어 실력을 향상시키고 싶다는 마음을 가볍게 표현합니다.\n",
    "\n",
    "예시 요약 결과\n",
    "최소 대학 생활부터 함께 한 매우 친밀한 사이의 두 사용자가 코로나가 잠잠해졌을 때 방문하고 싶은 해외 여행지에 대해 일상적이고 가벼운 톤으로 대화하고 있습니다.\n",
    "여행지로는 하와이, 괌, 스위스, 호주, 베트남 다낭 등을 언급하며 남편과의 연락 관련 다툼이나 졸업여행 관련 추억을 회상합니다.\n",
    "또한 여행 중 발생하는 위험에 대한 우려도 표하고 있으며, 해외여행 시 언어 장벽의 어려움을 인식하고 영어 실력을 향상시키고 싶다는 마음을 가볍게 표현합니다.\n",
    "    \n",
    "아래 사용자 대화에 대해 3문장 내로 요약해주세요:\"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf76b6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_eval_data():\n",
    "    with open('./res/eval_data.pickle', 'rb') as f:\n",
    "        eval_data = pickle.load(f)\n",
    "\n",
    "    return eval_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0272f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6216baaf150f47dd9320adca461968ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = 'gpt-4.1-mini'\n",
    "\n",
    "summary_result_dict = {model: []}\n",
    "prompt = get_summary_prompt()\n",
    "for i in range(5):\n",
    "    conversation = get_eval_data()[i]\n",
    "    summary = summarize(\n",
    "        conversation=conversation,\n",
    "        prompt=prompt,\n",
    "        model=model\n",
    "    )\n",
    "    summary_result_dict[model].append({'index' : i, 'summary' : summary, \"conversation\" : conversation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "796c3343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt-4.1-mini': [{'index': 0,\n",
       "   'summary': '1. 대화 참여자 파악: 두 명(P01, P02)이 친근한 사이로 서울에서 갈 만한 디저트 카페와 전시회에 대해 이야기하고 있습니다.  \\n2. 주제 식별: 서울에서 디저트 카페 방문과 대림 전시회 관람 계획이 주요 주제입니다.  \\n3. 핵심 내용 추출: P02는 달달한 빵이나 조각케익을 먹고 싶어 하고, P01은 너무 단 것은 싫어하며 마카롱과 케이크는 별로라고 합니다. 두 사람은 서울에서 디저트 카페에 가기로 하고, P01은 대림 전시회도 가고 싶어 합니다.  \\n4. 감정과 태도 분석: 두 사람 모두 가벼운 기대감과 긍정적인 태도를 보이며, 함께 외출할 계획에 즐거워합니다.  \\n5. 맥락 이해: 평소 디저트 카페 방문이 드문 P02가 오랜만에 가고 싶어 하고, P01은 서울에서의 문화 활동도 함께 제안합니다.  \\n6. 특이사항 기록: 대림 전시회가 무료라는 점에 두 사람이 호감을 보입니다.  \\n\\n요약:  \\n두 명이 서울에서 디저트 카페와 대림 전시회 방문을 계획하며, P02는 달콤한 빵과 조각케익을 선호하고 P01은 너무 단 디저트는 피하려 합니다. 두 사람은 함께 외출할 기대감에 긍정적이며, 대림 전시회의 무료 관람에 관심을 보입니다.',\n",
       "   'conversation': 'P01: 서울에 갈곳 없나\\nP02: 누난요새 디저트카페 이런곳가고싶다\\nP02: 안가본지오래돼서\\nP01: 어디요?\\nP02: 그냥 빵집이런곳\\nP01: 디저트 근데 누나 마카롱같은거 싫어하잖아\\nP02: 달달한거 먹고싶어\\nP02: 근데 빵은먹잖아\\nP01: 단거 투성이들 별로 싫어하지않나\\nP02: 아 그렇게 단거말고\\nP01: 디저트하면 마카롱밖에 생각안남\\nP02: 그냥 뭐 그냥 빵들\\nP01: 아하...\\nP02: 마카롱을 그냥 없애봐\\nP01: 나는 너무 달면 별로야 키키\\nP02: 빵도 달음\\nP01: 난 케익도 싫어\\nP02: 나도 난케익그냥 조각케익정도?\\nP01: 난 솔직히 그냥 조각케익 정도\\nP02: 응응  조각케익이  먹기조아\\nP01: 큰거 하나사면 별로임\\nP02: 그건 이제 사람 많을 때\\nP01: 근데 조각케익은 주제넘게 비싸\\nP02: ... 그거였군\\nP01: 서울에 디저트 카페 가보자\\nP02: 오 진짜 가자 ㅜㅜ\\nP01: 대림에 나는 전시회 가고싶어\\nP02: *** 안가려해  ?\\nP02: 거기머하는데\\nP01: 예전에 가보고싶엇어\\nP02: 뭔데\\nP01: 저기 공짜라서 좋아했음 키키\\nP02: 키키 공짜좋지'},\n",
       "  {'index': 1,\n",
       "   'summary': '1. 대화 참여자 파악: 두 명(P01, P02)이 친근한 사이로 일상적인 대화를 나누고 있습니다.  \\n2. 주제 식별: 방울토마토를 잘 안 먹는 습관, 춘천 메기찜집과 남한산성 맛집(메밀국수집, 빵집), 계곡과 주차 팁 등 여행 및 음식 관련 이야기입니다.  \\n3. 핵심 내용 추출: 방울토마토는 씻어 놓아야 잘 먹게 되고, 춘천 메기찜집은 시레기와 수제비가 들어가 맛있으며 후식 과일도 준다는 점, 남한산성 근처 메밀국수집과 빵집, 계곡 풍경과 주차 팁을 공유합니다.  \\n4. 감정과 태도 분석: 두 사람 모두 음식과 여행지에 대해 즐거워하고 기대하는 긍정적이고 유쾌한 태도를 보입니다.  \\n5. 맥락 이해: 평소 식습관과 맛집 탐방, 여행 계획을 친근하게 나누는 대화입니다.  \\n6. 특이사항 기록: 메기찜과 시레기, 수제비 조합에 대한 상세한 묘사와 남한산성 맛집 주차 팁이 눈에 띕니다.  \\n\\n요약:  \\n두 친구가 방울토마토를 잘 안 먹는 습관을 공유하며, 춘천 메기찜집과 남한산성 맛집(메밀국수집, 빵집) 방문을 계획합니다. 음식과 여행지에 대한 상세한 설명과 주차 팁을 나누며 즐거운 대화를 이어갑니다.',\n",
       "   'conversation': 'P02: 식후땡으로 방울토마토로 결정함\\nP01: 방토는 사랑이지\\nP02: 근데 이상하게 잘 안먹어져서 맨날 방치\\nP01: 나도 그래서 버린 과일 넘 많음\\nP02: 그쳐 누가 씻어서 먹게 놔주면 되는데\\nP01: 응 씻어서 그릇에 담아 눈앞에 대령해줄때\\nP02: 맞아 그럼 잘 먹을수잇어여\\nP01: 하하 요즘은 과일주는 식당이 그렇게 많지않아\\nP02: 근데 내가 씻어서 내가 먹기는 넘 귀차나\\nP01: 하하\\nP02: 이럴땐 또 엄마찬스인데\\nP01: 춘천에 메기찜집이 있어\\nP01: 거기 시레기랑 그런거 엄청 넣어주거든 찜인데 수제비도 들어가지\\nP02: 자꾸 이럴꺼임?\\nP01: 근데 거기 다먹으면 후식 과일도 줘 짱이야\\nP02: 나 춘천가야하자나\\nP01: 갈곳이 점점 많아짐 하하\\nP02: 시레기 겁나 좋아하는데 !\\nP01: 나도 하하\\nP02: 이건 좀더 끌린다 마니마니\\nP01: 시레기 한줄기에 메기찜 한점싸서  말아 그리고 그 위에 수제비 한점을 올려\\nP02: 하 왜그래 도대체\\nP01: 하하\\nP02: 너무 비유가 상세하자나 키키 그려지게\\nP01: 그걸 한입 크게 벌려서 앙  오물오물씹으면\\nP02: 잔인한 사람\\nP01: 메기의 담백함과 시레기에서 나오는 육즙이 퍼져\\nP01: 그때 수제비가 약간 목을 막히게 할때 국물을 한입 딱\\nP02: 키키 벌칙수행인가 나는\\nP01: 하하 짱웃\\nP02: 언제붜 이렇게 잔인햇져?\\nP01: 널 못만난 순간부터  후\\nP02: 난 이미 비어킹때부터 고통받앗어\\nP01: 하하 날 제발 놔줘 하하\\nP02: 키키난 붙들고 잇겟다고\\nP01: 그러고보니... 남한산성의 맛집도 소곤소곤 얘기해주고싶네 메밀국수집인디\\nP02: 아 그것도 저번에 들어본거같은데\\nP01: 옆에 계곡이 오짐\\nP02: 메밀국수는 또 처음이네 ?이런\\nP01: 하하 옆에 엄청난 계곡이 있음\\nP01: **이 친구들이 놀 높이의 계곡이지\\nP02: 키키 어째서 엄청나죠\\nP01: 제일 깊은 위치는 내 무릎?\\nP02: 키키 헐 이건 또 눈이 번쩍할소식\\nP01: 근데 미니 폭포도 흐르네?  하하 근데 또 넓기도 하지\\nP02: 와우  검색할래\\nP01: 빵집과 메밀국수집 사이에 계곡이 있지\\nP02: 일거양득\\nP01: 남한산성 위베이크  검색 ㄱㄱ\\nP02: 위까지만 쳣는데도 나옴\\nP01: 하하 한가지 팁을 주자면\\nP02: 키키 하 팁죠치\\nP01: 주말엔 사람이 많으니 위베이크 주차장보단 메밀국수집 주차장에 차대는걸 추천함\\nP02: 오 메밀국수도 좋아함\\nP01: 메밀국수 널널 위베이크 아수라장\\nP02: 그럼 난 메밀국수집을 가겟어\\nP01: 계곡을 보았냐며\\nP02: 하 근데 계곡도 보기전에\\nP01: 하하\\nP02: 빵집이 눈에띈다네?\\nP01: 하지만 생각보다 빵이 맛있진 않다는 함정\\nP02: 아 사진에 당할뻔\\nP01: 하하 비싸기만 비싸고\\nP02: 가바야지\\nP01: 국수에 메밀전병에 감자전  이 조합으로 먹고 물놀이  그럼 신선놀음\\nP02: 국수에 맛잇겟다 배부른데\\nP01: 침이 꼴깍\\nP02: 배가 남산만\\nP01: 하하 남산쓰'},\n",
       "  {'index': 2,\n",
       "   'summary': '1. 대화 참여자 파악: 두 명의 친구 사이로 보이며, 친근한 말투로 대화하고 있습니다.  \\n2. 주제 식별: P02의 과거 병원 입원 경험과 그 원인, 병원 방문의 중요성에 대해 이야기합니다.  \\n3. 핵심 내용 추출: P02가 낙지소면을 먹고 소화기관 염증으로 한 달간 병원에 가지 않아 입원했으며, 이후 후회하는 내용입니다.  \\n4. 감정과 태도 분석: P01은 걱정과 안타까움을 표현하고, P02는 후회와 반성을 나타냅니다.  \\n5. 맥락 이해: 건강 문제를 가볍게 여기지 말고 아프면 즉시 병원에 가야 한다는 교훈적 대화입니다.  \\n6. 특이사항 기록: P02가 병원 방문을 미뤄 병이 악화된 점과 그로 인해 체중이 많이 빠진 점이 눈에 띕니다.  \\n\\n요약: 두 친구가 P02의 낙지소면 섭취 후 소화기관 염증으로 한 달간 병원에 가지 않아 입원한 경험을 나누며, P01은 걱정하고 P02는 후회합니다. 이 대화는 아플 때 즉시 병원에 가야 한다는 교훈을 담고 있습니다.',\n",
       "   'conversation': 'P01: 병원에 입원 해본 적 있어?\\nP02: 응 키키 나 군 입대하기 전에 했었어\\nP01: 헐 키키 무슨 일로 입원한 거야?\\nP02: 키키 그때 뭘 잘못 먹었는지 소화기관에 염증이 다 나가지고 ㅠㅠ\\nP01: 아 배탈이 난 거구나 ㅠㅠ\\nP01: 뭐 먹었어!\\nP02: 낙지소면 먹었었는데 ㅠㅠ 아프고 나서 병원을 안 갔더니 엄청 심해져가지고 입원 했었어\\nP01: 헐 키키 낙지가 문제 있었네 ㅡㅡ\\nP01: 이런 위세척 한 거야?\\nP02: 아니 키키\\nP02: 낙지소면 먹고 아팠는데 거의 한 달 병원 안 갔거든... 하하\\nP02: 세척하기엔 늦었지\\nP01: 헐 한 달 동안 아플 수 있어?\\nP01: 미련해...\\nP01: 빨리 갔어야지!\\nP01: 그러다가 큰일 나!\\nP02: 이게 엄청 심하게 아픈 게 아니었어 ㅠㅠ\\nP02: 아프다 말고 아프다 말고 이래서 냅뒀는데 이게 염증이 엄청 번져가지고 ㅠㅠ\\nP01: 아하...\\nP01: 병을 더 키웠구나 ㅠㅠ\\nP01: 어떻게 참았대\\nP02: 원래 병원을 잘 안 가는 편이야 키키\\nP02: 덕분에 살만 엄청 빠졌었지\\nP01: 헉 키키 그래도 아프면 가야지~\\nP01: 미련해 정말!\\nP02: 키키 그러게 ㅠㅠ\\nP02: 나도 그때 엄청 후회 했어 ㅠㅠ\\nP02: 일찍 갔으면 그렇게까지 아프진 않았을 텐데\\nP01: 글쎄\\nP01: 엄청 고생했네 ㅜㅜ\\nP01: 다음부턴 조금이라도 아프면 병원 가!\\nP02: 응응 키키 그래야지!\\nP02: 그래도 그때 말곤 입원한 적 없어서 건강한 거 같아 키키'},\n",
       "  {'index': 3,\n",
       "   'summary': '1. 두 명의 친구가 폴로 직구 경험과 미국 백화점 직구의 장단점, 환율 문제에 대해 이야기하며 서로 정보를 공유합니다.  \\n2. 직구 과정의 어려움과 할인, 쿠폰 혜택에 대해 긍정적으로 평가하고, 한국 내 구매대행 서비스에 대한 기대감을 표현합니다.  \\n3. 대화 후반에는 체크셔츠와 개발자 이미지에 관한 농담을 주고받으며 친근하고 유쾌한 분위기를 유지합니다.\\n\\n요약:  \\n두 친구가 폴로 직구와 미국 백화점 직구 경험, 환율과 할인 혜택을 공유하며 구매대행 서비스에 관심을 보입니다. 이후 체크셔츠와 개발자 이미지를 유머러스하게 이야기하며 친근한 대화를 나눕니다.',\n",
       "   'conversation': 'P01: 너 폴로 직구 하지 않았어?\\nP01: 어디서 한거야\\nP02: 아니 폴로 직구 진짜 미쳤어 너무어려워\\nP02: 폴로 공홈에 막혀가지고 되는데 찾느라 진짜 지구 한바퀴 돈 듯\\nP01: 키키 지구를 왜돌아\\nP01: 아니 키키 공홈에샤 하면 많이 싼가\\nP01: 우리나라 들어오면 왤캐 비싼겨\\nP02: 아니 공홈은 진짜 싸고 공홈은 거의 막혀서 나는 공홈 말고 미국 백화점 직구 ...\\nP01: 아...ㅠ 미국 백화점은 거품 없나보네\\nP02: 할인도 해 심지어\\nP02: 쿠폰도 준다구 넘 조아\\nP01: 오... 오히려 좋네\\nP01: 미국 여행가면 무짝권 백화점 투어\\nP01: 엇 근데 지금 달러 환율 너무 높지 않나 키키\\nP02: 아니 지금 구매대행 신청해놨어\\nP02: 달러 1200 원 고정 환율\\nP01: 왤캐 비싸\\nP02: 좀 높긴 하지만 ...\\nP01: 에; 그래도 싸?\\nP02: 그래도 카드 수수료랑 비슷 ...\\nP02: 아니 애초에 한국 보다 싸\\nP01: 쿠팡 이런곳에서도 대행 해주면 좋겠다\\nP01: 백화점보다 싸고 미국보단 조금 비싸도 편하면 잘 이용할 듯\\nP02: 맞아 엄청 잘 되어있더라 키키\\nP02: 말 나온 김에 입고됐나 봐야지\\nP01: 폴로랑 다른 브랜드들도 다 있나?\\nP02: 웅 근데 메종키츠네 이런건 없어서 조금 슬펐어 ...\\nP02: 물론 난 우익 아니긴 하지만 여우 좀 귀엽\\nP01: 오 대박이네 나도 다음에 한 번 이용해 봐야겠다.\\nP02: 웅 이용해봥\\nP02: 추천인은 나 알지? ^_^\\nP01: 절때 못참지 무조건 비워둬야지\\nP01: 여름시즌은 거의 다 지나가니까 가을 옷들을 좀 사볼까 거런거\\nP01: [이모티콘]\\nP02: ? 바로 너도 폴로 셔츠 하나 사\\nP02: 가디건도 남자 사이즈는 있으려나\\nP01: 체크셔츠 아니지?\\nP01: 체크셔츠는 못입어\\nP02: 키키 개발자 국룰 체크셔츠 ㅜ\\nP02: 하지만 난 하얀 셔츠 샀어\\nP01: ㅜㅜ 직업 공개\\nP01: 체크셔츠 입으면 혹시 개발자세요 ㅡㅡ?\\nP02: 하얀 셔츠만 5개지만 이정돈 괜찮지 않나 ... 라는\\nP01: 키키 각각 뭔가 조금씩...\\nP02: 다 다르다구요 !\\nP01: 다른... 그런게 있지 에... 알파값이 조금 다르다던가\\nP02: 조금씩 다른 ... 로고도 브랜드도 다르고 핏도 다른 ...\\nP01: 로고 중요하지 핏도 중요하고 맞지\\nP02: 알파값 ...? 벌써 개발자 확정\\nP02: 삐빅 개발자입니다\\nP01: [이모티콘]\\nP01: 바로 빨간색에 초록/검정 줄 가 있는 체크셔츠 풀매수\\nP02: 아 키키 빨간파란하양 체크\\nP02: 개발자 확실 첫번째 사진 승인\\nP01: 키키 개웃기네 저거 진짜 저런 옷장 있을 것만 같아\\nP01: 레알 체크빌런 있는데\\nP02: 키키 너네 회사에?\\nP02: 아니 근데 개발자는 다 체크셔츠만 입냐구 ㅜ\\nP01: 다 아니야 ㅠㅠ\\nP01: 그러나 가끔 있는 체크셔츠만 입는 분은 개발자가 맞아\\nP02: 에 ... 그건 조금 곤란\\nP01: 아니 왜 공대생 프레임 스스로 뒤집어 써\\nP01: 학교엔 근데 진짜 많긴 했어\\nP01: 그런건 어디 전문적으로 사는 매장이 있는 건가...'},\n",
       "  {'index': 4,\n",
       "   'summary': '1. 대화 참여자는 두 명으로, 친한 친구 사이로 보입니다.  \\n2. 주요 주제는 싸이월드 복구와 추억 회상, 그리고 최근 받는 다양한 정부 지원금과 장학금에 관한 이야기입니다.  \\n3. 두 사람은 싸이월드 사진과 도토리 충전 등 옛 추억을 즐겁게 회상하며, 현재는 지원금 덕분에 경제적 도움을 받고 있어 긍정적인 태도를 보입니다.  \\n\\n요약:  \\n두 친구가 싸이월드 복구와 옛 추억을 즐겁게 나누고, 최근 다양한 정부 지원금과 장학금 덕분에 경제적 도움을 받고 있음을 긍정적으로 이야기합니다.',\n",
       "   'conversation': 'P01: 맞다요즘 싸이월드 새로 생겼다매\\nP02: 나 싸이월드 복구하고 싶다\\nP01: 웅 키키귀여우뉴사진\\nP02: 진짜 추억돋네\\nP01: 짱많아 옛날 사진들\\nP01: 맨날 퍼가요~ 이거 했자나\\nP02: 맞아 싸이월드 미니미\\nP01: 추억 돋아서 너무조아\\nP02: 꾸미는거\\nP01: 마자\\nP02: 재밌었는데\\nP01: 귀여워 도토리충전\\nP02: 네이트온도 하고\\nP02: 도토리도 환불해준대자나\\nP01: 마자 키키개웃겨\\nP01: 요즘 사회적으로 멀 자꾸하나바\\nP02: 대박이야 진짜\\nP02: 그니깐 키키\\nP01: 아니 나오늘 엄마가 뭐 신청해달라그래서\\nP02: 웅\\nP01: 지원금 ? 신청함\\nP01: 진짜 요즘 지원금 엄청 많이 받았어\\nP02: 와 대박\\nP01: 뭔지는 잘 모르는데 이것저것 지원해주는거 많아서 좋은듯\\nP02: 다행이다\\nP01: 국가제도가 진짜 괜차나\\nP01: 학교에서도\\nP02: 두분다\\nP01: 맨날 장학금 해준다고\\nP02: 일을 못하는\\nP01: 이것저것 지원해주자나\\nP02: 상황이셔서 더\\nP01: 마자ㅠㅠ\\nP02: 도움주시고\\nP01: 나 그래서 진짜 그런거로\\nP02: 다행이다그래도\\nP01: 돈 마니받앗어\\nP02: 와대박'}]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c534228",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9570a425",
   "metadata": {},
   "source": [
    "## 주요 키워드 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ebfc4099",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_keyword_prompt():\n",
    "    conv_train = get_train_data()[18]\n",
    "    prompt = f\"\"\"당신은 키워드 요약 전문가입니다. 사용자 대화들이 주어졌을 때 키워드 추출하는 것이 당신의 목표입니다. 키워드를 추출할 때는 다음 단계를 따라주세요.\n",
    "\n",
    "1. 대화 참여자 파악: 대화에 참여하는 사람들의 수와 관계를 파악합니다.\n",
    "2. 주제 식별: 대화의 주요 주제와 부차적인 주제들을 식별합니다.\n",
    "3. 핵심 내용 추출: 각 주제에 대한 중요한 정보나 의견을 추출합니다.\n",
    "4. 감정과 태도 분석: 대화 참여자들의 감정이나 태도를 파악합니다.\n",
    "5. 맥락 이해: 대화의 전반적인 맥락과 배경을 이해합니다.\n",
    "6. 특이사항 기록: 대화 중 특별히 눈에 띄는 점이나 중요한 사건을 기록합니다.\n",
    "7. 키워드 추출 : 요약문과 대화 기록을 바탕으로 위의 단계에서 얻은 정보를 바탕으로 간결하고 명확한 키워드들을 작성합니다.\n",
    "각 단계를 수행한 후, 최종적으로 전체 대화를 10 개 내외의 키워드로 요약해주세요.\n",
    "8. 키워드만 추출해주세요. 나머지는 출력은 절대 하지 마세요.\n",
    "\"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d5e16747",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keyword(conversation, summary, prompt, temperature=0.0, model='gpt-4.1-nano'):\n",
    "    if len(conversation) > MAX_LEN:\n",
    "        conversation = shorten_conv(conversation)\n",
    "\n",
    "    prompt = prompt + '\\n\\n' + conversation + '\\n\\n' + summary\n",
    "\n",
    "    if 'gpt' in model:\n",
    "        client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "        completion = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[{'role': 'user', 'content': prompt}],\n",
    "            temperature=temperature\n",
    "        )\n",
    "\n",
    "        return completion.choices[0].message.content\n",
    "    elif 'gemini' in model:\n",
    "        genai.configure(api_key=GOOGLE_API_KEY)\n",
    "        client = genai.GenerativeModel(model)\n",
    "        response = client.generate_content(\n",
    "            contents=prompt,\n",
    "            safety_settings={\n",
    "                HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE\n",
    "            }\n",
    "        )\n",
    "        time.sleep(1)\n",
    "\n",
    "        return response.text\n",
    "    elif 'claude' in model:\n",
    "        client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)\n",
    "        message = client.messages.create(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=temperature,\n",
    "            max_tokens=1024\n",
    "        )\n",
    "\n",
    "        return message.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d4e1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b38de022030460b8502f50427391e58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = get_keyword_prompt()\n",
    "for i in range(5):\n",
    "    conversation = get_eval_data()[i]\n",
    "    keyword = extract_keyword(\n",
    "        conversation=conversation,\n",
    "        summary=summary,\n",
    "        prompt=prompt,\n",
    "        model=model\n",
    "    )\n",
    "    summary_result_dict[model][i]['keyword'] = keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4b301371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt-4.1-mini': [{'index': 0,\n",
       "   'summary': '1. 대화 참여자 파악: 두 명(P01, P02)이 친근한 사이로 서울에서 갈 만한 디저트 카페와 전시회에 대해 이야기하고 있습니다.  \\n2. 주제 식별: 서울에서 디저트 카페 방문과 대림 전시회 관람 계획이 주요 주제입니다.  \\n3. 핵심 내용 추출: P02는 달달한 빵이나 조각케익을 먹고 싶어 하고, P01은 너무 단 것은 싫어하며 마카롱과 케이크는 별로라고 합니다. 두 사람은 서울에서 디저트 카페에 가기로 하고, P01은 대림 전시회도 가고 싶어 합니다.  \\n4. 감정과 태도 분석: 두 사람 모두 가벼운 기대감과 긍정적인 태도를 보이며, 함께 외출할 계획에 즐거워합니다.  \\n5. 맥락 이해: 평소 디저트 카페 방문이 드문 P02가 오랜만에 가고 싶어 하고, P01은 서울에서의 문화 활동도 함께 제안합니다.  \\n6. 특이사항 기록: 대림 전시회가 무료라는 점에 두 사람이 호감을 보입니다.  \\n\\n요약:  \\n두 명이 서울에서 디저트 카페와 대림 전시회 방문을 계획하며, P02는 달콤한 빵과 조각케익을 선호하고 P01은 너무 단 디저트는 피하려 합니다. 두 사람은 함께 외출할 기대감에 긍정적이며, 대림 전시회의 무료 관람에 관심을 보입니다.',\n",
       "   'conversation': 'P01: 서울에 갈곳 없나\\nP02: 누난요새 디저트카페 이런곳가고싶다\\nP02: 안가본지오래돼서\\nP01: 어디요?\\nP02: 그냥 빵집이런곳\\nP01: 디저트 근데 누나 마카롱같은거 싫어하잖아\\nP02: 달달한거 먹고싶어\\nP02: 근데 빵은먹잖아\\nP01: 단거 투성이들 별로 싫어하지않나\\nP02: 아 그렇게 단거말고\\nP01: 디저트하면 마카롱밖에 생각안남\\nP02: 그냥 뭐 그냥 빵들\\nP01: 아하...\\nP02: 마카롱을 그냥 없애봐\\nP01: 나는 너무 달면 별로야 키키\\nP02: 빵도 달음\\nP01: 난 케익도 싫어\\nP02: 나도 난케익그냥 조각케익정도?\\nP01: 난 솔직히 그냥 조각케익 정도\\nP02: 응응  조각케익이  먹기조아\\nP01: 큰거 하나사면 별로임\\nP02: 그건 이제 사람 많을 때\\nP01: 근데 조각케익은 주제넘게 비싸\\nP02: ... 그거였군\\nP01: 서울에 디저트 카페 가보자\\nP02: 오 진짜 가자 ㅜㅜ\\nP01: 대림에 나는 전시회 가고싶어\\nP02: *** 안가려해  ?\\nP02: 거기머하는데\\nP01: 예전에 가보고싶엇어\\nP02: 뭔데\\nP01: 저기 공짜라서 좋아했음 키키\\nP02: 키키 공짜좋지',\n",
       "   'keyword': '서울, 디저트카페, 빵집, 마카롱, 단맛, 조각케익, 가격, 전시회, 대림, 무료'},\n",
       "  {'index': 1,\n",
       "   'summary': '1. 대화 참여자 파악: 두 명(P01, P02)이 친근한 사이로 일상적인 대화를 나누고 있습니다.  \\n2. 주제 식별: 방울토마토를 잘 안 먹는 습관, 춘천 메기찜집과 남한산성 맛집(메밀국수집, 빵집), 계곡과 주차 팁 등 여행 및 음식 관련 이야기입니다.  \\n3. 핵심 내용 추출: 방울토마토는 씻어 놓아야 잘 먹게 되고, 춘천 메기찜집은 시레기와 수제비가 들어가 맛있으며 후식 과일도 준다는 점, 남한산성 근처 메밀국수집과 빵집, 계곡 풍경과 주차 팁을 공유합니다.  \\n4. 감정과 태도 분석: 두 사람 모두 음식과 여행지에 대해 즐거워하고 기대하는 긍정적이고 유쾌한 태도를 보입니다.  \\n5. 맥락 이해: 평소 식습관과 맛집 탐방, 여행 계획을 친근하게 나누는 대화입니다.  \\n6. 특이사항 기록: 메기찜과 시레기, 수제비 조합에 대한 상세한 묘사와 남한산성 맛집 주차 팁이 눈에 띕니다.  \\n\\n요약:  \\n두 친구가 방울토마토를 잘 안 먹는 습관을 공유하며, 춘천 메기찜집과 남한산성 맛집(메밀국수집, 빵집) 방문을 계획합니다. 음식과 여행지에 대한 상세한 설명과 주차 팁을 나누며 즐거운 대화를 이어갑니다.',\n",
       "   'conversation': 'P02: 식후땡으로 방울토마토로 결정함\\nP01: 방토는 사랑이지\\nP02: 근데 이상하게 잘 안먹어져서 맨날 방치\\nP01: 나도 그래서 버린 과일 넘 많음\\nP02: 그쳐 누가 씻어서 먹게 놔주면 되는데\\nP01: 응 씻어서 그릇에 담아 눈앞에 대령해줄때\\nP02: 맞아 그럼 잘 먹을수잇어여\\nP01: 하하 요즘은 과일주는 식당이 그렇게 많지않아\\nP02: 근데 내가 씻어서 내가 먹기는 넘 귀차나\\nP01: 하하\\nP02: 이럴땐 또 엄마찬스인데\\nP01: 춘천에 메기찜집이 있어\\nP01: 거기 시레기랑 그런거 엄청 넣어주거든 찜인데 수제비도 들어가지\\nP02: 자꾸 이럴꺼임?\\nP01: 근데 거기 다먹으면 후식 과일도 줘 짱이야\\nP02: 나 춘천가야하자나\\nP01: 갈곳이 점점 많아짐 하하\\nP02: 시레기 겁나 좋아하는데 !\\nP01: 나도 하하\\nP02: 이건 좀더 끌린다 마니마니\\nP01: 시레기 한줄기에 메기찜 한점싸서  말아 그리고 그 위에 수제비 한점을 올려\\nP02: 하 왜그래 도대체\\nP01: 하하\\nP02: 너무 비유가 상세하자나 키키 그려지게\\nP01: 그걸 한입 크게 벌려서 앙  오물오물씹으면\\nP02: 잔인한 사람\\nP01: 메기의 담백함과 시레기에서 나오는 육즙이 퍼져\\nP01: 그때 수제비가 약간 목을 막히게 할때 국물을 한입 딱\\nP02: 키키 벌칙수행인가 나는\\nP01: 하하 짱웃\\nP02: 언제붜 이렇게 잔인햇져?\\nP01: 널 못만난 순간부터  후\\nP02: 난 이미 비어킹때부터 고통받앗어\\nP01: 하하 날 제발 놔줘 하하\\nP02: 키키난 붙들고 잇겟다고\\nP01: 그러고보니... 남한산성의 맛집도 소곤소곤 얘기해주고싶네 메밀국수집인디\\nP02: 아 그것도 저번에 들어본거같은데\\nP01: 옆에 계곡이 오짐\\nP02: 메밀국수는 또 처음이네 ?이런\\nP01: 하하 옆에 엄청난 계곡이 있음\\nP01: **이 친구들이 놀 높이의 계곡이지\\nP02: 키키 어째서 엄청나죠\\nP01: 제일 깊은 위치는 내 무릎?\\nP02: 키키 헐 이건 또 눈이 번쩍할소식\\nP01: 근데 미니 폭포도 흐르네?  하하 근데 또 넓기도 하지\\nP02: 와우  검색할래\\nP01: 빵집과 메밀국수집 사이에 계곡이 있지\\nP02: 일거양득\\nP01: 남한산성 위베이크  검색 ㄱㄱ\\nP02: 위까지만 쳣는데도 나옴\\nP01: 하하 한가지 팁을 주자면\\nP02: 키키 하 팁죠치\\nP01: 주말엔 사람이 많으니 위베이크 주차장보단 메밀국수집 주차장에 차대는걸 추천함\\nP02: 오 메밀국수도 좋아함\\nP01: 메밀국수 널널 위베이크 아수라장\\nP02: 그럼 난 메밀국수집을 가겟어\\nP01: 계곡을 보았냐며\\nP02: 하 근데 계곡도 보기전에\\nP01: 하하\\nP02: 빵집이 눈에띈다네?\\nP01: 하지만 생각보다 빵이 맛있진 않다는 함정\\nP02: 아 사진에 당할뻔\\nP01: 하하 비싸기만 비싸고\\nP02: 가바야지\\nP01: 국수에 메밀전병에 감자전  이 조합으로 먹고 물놀이  그럼 신선놀음\\nP02: 국수에 맛잇겟다 배부른데\\nP01: 침이 꼴깍\\nP02: 배가 남산만\\nP01: 하하 남산쓰',\n",
       "   'keyword': '방울토마토, 과일섭취, 귀차니즘, 엄마찬스, 춘천 메기찜, 시레기, 수제비, 남한산성 맛집, 메밀국수, 계곡, 주차팁'},\n",
       "  {'index': 2,\n",
       "   'summary': '1. 대화 참여자 파악: 두 명의 친구 사이로 보이며, 친근한 말투로 대화하고 있습니다.  \\n2. 주제 식별: P02의 과거 병원 입원 경험과 그 원인, 병원 방문의 중요성에 대해 이야기합니다.  \\n3. 핵심 내용 추출: P02가 낙지소면을 먹고 소화기관 염증으로 한 달간 병원에 가지 않아 입원했으며, 이후 후회하는 내용입니다.  \\n4. 감정과 태도 분석: P01은 걱정과 안타까움을 표현하고, P02는 후회와 반성을 나타냅니다.  \\n5. 맥락 이해: 건강 문제를 가볍게 여기지 말고 아프면 즉시 병원에 가야 한다는 교훈적 대화입니다.  \\n6. 특이사항 기록: P02가 병원 방문을 미뤄 병이 악화된 점과 그로 인해 체중이 많이 빠진 점이 눈에 띕니다.  \\n\\n요약: 두 친구가 P02의 낙지소면 섭취 후 소화기관 염증으로 한 달간 병원에 가지 않아 입원한 경험을 나누며, P01은 걱정하고 P02는 후회합니다. 이 대화는 아플 때 즉시 병원에 가야 한다는 교훈을 담고 있습니다.',\n",
       "   'conversation': 'P01: 병원에 입원 해본 적 있어?\\nP02: 응 키키 나 군 입대하기 전에 했었어\\nP01: 헐 키키 무슨 일로 입원한 거야?\\nP02: 키키 그때 뭘 잘못 먹었는지 소화기관에 염증이 다 나가지고 ㅠㅠ\\nP01: 아 배탈이 난 거구나 ㅠㅠ\\nP01: 뭐 먹었어!\\nP02: 낙지소면 먹었었는데 ㅠㅠ 아프고 나서 병원을 안 갔더니 엄청 심해져가지고 입원 했었어\\nP01: 헐 키키 낙지가 문제 있었네 ㅡㅡ\\nP01: 이런 위세척 한 거야?\\nP02: 아니 키키\\nP02: 낙지소면 먹고 아팠는데 거의 한 달 병원 안 갔거든... 하하\\nP02: 세척하기엔 늦었지\\nP01: 헐 한 달 동안 아플 수 있어?\\nP01: 미련해...\\nP01: 빨리 갔어야지!\\nP01: 그러다가 큰일 나!\\nP02: 이게 엄청 심하게 아픈 게 아니었어 ㅠㅠ\\nP02: 아프다 말고 아프다 말고 이래서 냅뒀는데 이게 염증이 엄청 번져가지고 ㅠㅠ\\nP01: 아하...\\nP01: 병을 더 키웠구나 ㅠㅠ\\nP01: 어떻게 참았대\\nP02: 원래 병원을 잘 안 가는 편이야 키키\\nP02: 덕분에 살만 엄청 빠졌었지\\nP01: 헉 키키 그래도 아프면 가야지~\\nP01: 미련해 정말!\\nP02: 키키 그러게 ㅠㅠ\\nP02: 나도 그때 엄청 후회 했어 ㅠㅠ\\nP02: 일찍 갔으면 그렇게까지 아프진 않았을 텐데\\nP01: 글쎄\\nP01: 엄청 고생했네 ㅜㅜ\\nP01: 다음부턴 조금이라도 아프면 병원 가!\\nP02: 응응 키키 그래야지!\\nP02: 그래도 그때 말곤 입원한 적 없어서 건강한 거 같아 키키',\n",
       "   'keyword': '입원, 군 입대 전, 소화기관 염증, 낙지소면, 병원 지연, 염증 악화, 병원 미방문, 체중 감소, 후회, 건강 관리'},\n",
       "  {'index': 3,\n",
       "   'summary': '1. 두 명의 친구가 폴로 직구 경험과 미국 백화점 직구의 장단점, 환율 문제에 대해 이야기하며 서로 정보를 공유합니다.  \\n2. 직구 과정의 어려움과 할인, 쿠폰 혜택에 대해 긍정적으로 평가하고, 한국 내 구매대행 서비스에 대한 기대감을 표현합니다.  \\n3. 대화 후반에는 체크셔츠와 개발자 이미지에 관한 농담을 주고받으며 친근하고 유쾌한 분위기를 유지합니다.\\n\\n요약:  \\n두 친구가 폴로 직구와 미국 백화점 직구 경험, 환율과 할인 혜택을 공유하며 구매대행 서비스에 관심을 보입니다. 이후 체크셔츠와 개발자 이미지를 유머러스하게 이야기하며 친근한 대화를 나눕니다.',\n",
       "   'conversation': 'P01: 너 폴로 직구 하지 않았어?\\nP01: 어디서 한거야\\nP02: 아니 폴로 직구 진짜 미쳤어 너무어려워\\nP02: 폴로 공홈에 막혀가지고 되는데 찾느라 진짜 지구 한바퀴 돈 듯\\nP01: 키키 지구를 왜돌아\\nP01: 아니 키키 공홈에샤 하면 많이 싼가\\nP01: 우리나라 들어오면 왤캐 비싼겨\\nP02: 아니 공홈은 진짜 싸고 공홈은 거의 막혀서 나는 공홈 말고 미국 백화점 직구 ...\\nP01: 아...ㅠ 미국 백화점은 거품 없나보네\\nP02: 할인도 해 심지어\\nP02: 쿠폰도 준다구 넘 조아\\nP01: 오... 오히려 좋네\\nP01: 미국 여행가면 무짝권 백화점 투어\\nP01: 엇 근데 지금 달러 환율 너무 높지 않나 키키\\nP02: 아니 지금 구매대행 신청해놨어\\nP02: 달러 1200 원 고정 환율\\nP01: 왤캐 비싸\\nP02: 좀 높긴 하지만 ...\\nP01: 에; 그래도 싸?\\nP02: 그래도 카드 수수료랑 비슷 ...\\nP02: 아니 애초에 한국 보다 싸\\nP01: 쿠팡 이런곳에서도 대행 해주면 좋겠다\\nP01: 백화점보다 싸고 미국보단 조금 비싸도 편하면 잘 이용할 듯\\nP02: 맞아 엄청 잘 되어있더라 키키\\nP02: 말 나온 김에 입고됐나 봐야지\\nP01: 폴로랑 다른 브랜드들도 다 있나?\\nP02: 웅 근데 메종키츠네 이런건 없어서 조금 슬펐어 ...\\nP02: 물론 난 우익 아니긴 하지만 여우 좀 귀엽\\nP01: 오 대박이네 나도 다음에 한 번 이용해 봐야겠다.\\nP02: 웅 이용해봥\\nP02: 추천인은 나 알지? ^_^\\nP01: 절때 못참지 무조건 비워둬야지\\nP01: 여름시즌은 거의 다 지나가니까 가을 옷들을 좀 사볼까 거런거\\nP01: [이모티콘]\\nP02: ? 바로 너도 폴로 셔츠 하나 사\\nP02: 가디건도 남자 사이즈는 있으려나\\nP01: 체크셔츠 아니지?\\nP01: 체크셔츠는 못입어\\nP02: 키키 개발자 국룰 체크셔츠 ㅜ\\nP02: 하지만 난 하얀 셔츠 샀어\\nP01: ㅜㅜ 직업 공개\\nP01: 체크셔츠 입으면 혹시 개발자세요 ㅡㅡ?\\nP02: 하얀 셔츠만 5개지만 이정돈 괜찮지 않나 ... 라는\\nP01: 키키 각각 뭔가 조금씩...\\nP02: 다 다르다구요 !\\nP01: 다른... 그런게 있지 에... 알파값이 조금 다르다던가\\nP02: 조금씩 다른 ... 로고도 브랜드도 다르고 핏도 다른 ...\\nP01: 로고 중요하지 핏도 중요하고 맞지\\nP02: 알파값 ...? 벌써 개발자 확정\\nP02: 삐빅 개발자입니다\\nP01: [이모티콘]\\nP01: 바로 빨간색에 초록/검정 줄 가 있는 체크셔츠 풀매수\\nP02: 아 키키 빨간파란하양 체크\\nP02: 개발자 확실 첫번째 사진 승인\\nP01: 키키 개웃기네 저거 진짜 저런 옷장 있을 것만 같아\\nP01: 레알 체크빌런 있는데\\nP02: 키키 너네 회사에?\\nP02: 아니 근데 개발자는 다 체크셔츠만 입냐구 ㅜ\\nP01: 다 아니야 ㅠㅠ\\nP01: 그러나 가끔 있는 체크셔츠만 입는 분은 개발자가 맞아\\nP02: 에 ... 그건 조금 곤란\\nP01: 아니 왜 공대생 프레임 스스로 뒤집어 써\\nP01: 학교엔 근데 진짜 많긴 했어\\nP01: 그런건 어디 전문적으로 사는 매장이 있는 건가...',\n",
       "   'keyword': '폴로 직구, 미국 백화점, 공홈 직구, 환율, 구매대행, 할인 쿠폰, 브랜드 다양성, 체크셔츠, 개발자 패션, 친구 대화'},\n",
       "  {'index': 4,\n",
       "   'summary': '1. 대화 참여자는 두 명으로, 친한 친구 사이로 보입니다.  \\n2. 주요 주제는 싸이월드 복구와 추억 회상, 그리고 최근 받는 다양한 정부 지원금과 장학금에 관한 이야기입니다.  \\n3. 두 사람은 싸이월드 사진과 도토리 충전 등 옛 추억을 즐겁게 회상하며, 현재는 지원금 덕분에 경제적 도움을 받고 있어 긍정적인 태도를 보입니다.  \\n\\n요약:  \\n두 친구가 싸이월드 복구와 옛 추억을 즐겁게 나누고, 최근 다양한 정부 지원금과 장학금 덕분에 경제적 도움을 받고 있음을 긍정적으로 이야기합니다.',\n",
       "   'conversation': 'P01: 맞다요즘 싸이월드 새로 생겼다매\\nP02: 나 싸이월드 복구하고 싶다\\nP01: 웅 키키귀여우뉴사진\\nP02: 진짜 추억돋네\\nP01: 짱많아 옛날 사진들\\nP01: 맨날 퍼가요~ 이거 했자나\\nP02: 맞아 싸이월드 미니미\\nP01: 추억 돋아서 너무조아\\nP02: 꾸미는거\\nP01: 마자\\nP02: 재밌었는데\\nP01: 귀여워 도토리충전\\nP02: 네이트온도 하고\\nP02: 도토리도 환불해준대자나\\nP01: 마자 키키개웃겨\\nP01: 요즘 사회적으로 멀 자꾸하나바\\nP02: 대박이야 진짜\\nP02: 그니깐 키키\\nP01: 아니 나오늘 엄마가 뭐 신청해달라그래서\\nP02: 웅\\nP01: 지원금 ? 신청함\\nP01: 진짜 요즘 지원금 엄청 많이 받았어\\nP02: 와 대박\\nP01: 뭔지는 잘 모르는데 이것저것 지원해주는거 많아서 좋은듯\\nP02: 다행이다\\nP01: 국가제도가 진짜 괜차나\\nP01: 학교에서도\\nP02: 두분다\\nP01: 맨날 장학금 해준다고\\nP02: 일을 못하는\\nP01: 이것저것 지원해주자나\\nP02: 상황이셔서 더\\nP01: 마자ㅠㅠ\\nP02: 도움주시고\\nP01: 나 그래서 진짜 그런거로\\nP02: 다행이다그래도\\nP01: 돈 마니받앗어\\nP02: 와대박',\n",
       "   'keyword': '싸이월드, 추억, 사진복구, 도토리, 지원금, 장학금, 경제적 도움, 정부제도, 긍정적 태도, 친구 대화'}]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7054bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3037b640",
   "metadata": {},
   "source": [
    "## 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e4888bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P01: 서울에 갈곳 없나\n",
      "P02: 누난요새 디저트카페 이런곳가고싶다\n",
      "P02: 안가본지오래돼서\n",
      "P01: 어디요?\n",
      "P02: 그냥 빵집이런곳\n",
      "P01: 디저트 근데 누나 마카롱같은거 싫어하잖아\n",
      "P02: 달달한거 먹고싶어\n",
      "P02: 근데 빵은먹잖아\n",
      "P01: 단거 투성이들 별로 싫어하지않나\n",
      "P02: 아 그렇게 단거말고\n",
      "P01: 디저트하면 마카롱밖에 생각안남\n",
      "P02: 그냥 뭐 그냥 빵들\n",
      "P01: 아하...\n",
      "P02: 마카롱을 그냥 없애봐\n",
      "P01: 나는 너무 달면 별로야 키키\n",
      "P02: 빵도 달음\n",
      "P01: 난 케익도 싫어\n",
      "P02: 나도 난케익그냥 조각케익정도?\n",
      "P01: 난 솔직히 그냥 조각케익 정도\n",
      "P02: 응응  조각케익이  먹기조아\n",
      "P01: 큰거 하나사면 별로임\n",
      "P02: 그건 이제 사람 많을 때\n",
      "P01: 근데 조각케익은 주제넘게 비싸\n",
      "P02: ... 그거였군\n",
      "P01: 서울에 디저트 카페 가보자\n",
      "P02: 오 진짜 가자 ㅜㅜ\n",
      "P01: 대림에 나는 전시회 가고싶어\n",
      "P02: *** 안가려해  ?\n",
      "P02: 거기머하는데\n",
      "P01: 예전에 가보고싶엇어\n",
      "P02: 뭔데\n",
      "P01: 저기 공짜라서 좋아했음 키키\n",
      "P02: 키키 공짜좋지\n"
     ]
    }
   ],
   "source": [
    "print(summary_result_dict[model][0]['conversation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3b943897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 대화 참여자 파악: 두 명(P01, P02)이 친근한 사이로 서울에서 갈 만한 디저트 카페와 전시회에 대해 이야기하고 있습니다.  \n",
      "2. 주제 식별: 서울에서 디저트 카페 방문과 대림 전시회 관람 계획이 주요 주제입니다.  \n",
      "3. 핵심 내용 추출: P02는 달달한 빵이나 조각케익을 먹고 싶어 하고, P01은 너무 단 것은 싫어하며 마카롱과 케이크는 별로라고 합니다. 두 사람은 서울에서 디저트 카페에 가기로 하고, P01은 대림 전시회도 가고 싶어 합니다.  \n",
      "4. 감정과 태도 분석: 두 사람 모두 가벼운 기대감과 긍정적인 태도를 보이며, 함께 외출할 계획에 즐거워합니다.  \n",
      "5. 맥락 이해: 평소 디저트 카페 방문이 드문 P02가 오랜만에 가고 싶어 하고, P01은 서울에서의 문화 활동도 함께 제안합니다.  \n",
      "6. 특이사항 기록: 대림 전시회가 무료라는 점에 두 사람이 호감을 보입니다.  \n",
      "\n",
      "요약:  \n",
      "두 명이 서울에서 디저트 카페와 대림 전시회 방문을 계획하며, P02는 달콤한 빵과 조각케익을 선호하고 P01은 너무 단 디저트는 피하려 합니다. 두 사람은 함께 외출할 기대감에 긍정적이며, 대림 전시회의 무료 관람에 관심을 보입니다.\n"
     ]
    }
   ],
   "source": [
    "print(summary_result_dict[model][0]['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "46d499bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "서울, 디저트카페, 빵집, 마카롱, 단맛, 조각케익, 가격, 전시회, 대림, 무료\n"
     ]
    }
   ],
   "source": [
    "print(summary_result_dict[model][0]['keyword'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a88675f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
